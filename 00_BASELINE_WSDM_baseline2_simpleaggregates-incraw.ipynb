{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1643537698691,
     "user": {
      "displayName": "Markus",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08156928817414143810"
     },
     "user_tz": -60
    },
    "id": "59Atc0GfduwM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import gc; gc.enable()\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 25782,
     "status": "ok",
     "timestamp": 1643537467947,
     "user": {
      "displayName": "Markus",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08156928817414143810"
     },
     "user_tz": -60
    },
    "id": "_TgV5Op2b7Ei",
    "outputId": "b2dfcda1-356d-441b-b39f-d38302ca14a2",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20140109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20140125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  city    bd  gender  \\\n",
       "0  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0    male   \n",
       "1  f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=         1  13.0  20.0    male   \n",
       "2  zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=         1  13.0  18.0    male   \n",
       "3  8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=         1   1.0   0.0     NaN   \n",
       "4  K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=         1  13.0  35.0  female   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0             3.0              20131223.0  \n",
       "1             3.0              20131223.0  \n",
       "2             3.0              20131227.0  \n",
       "3             7.0              20140109.0  \n",
       "4             7.0              20140125.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading train csv\n",
    "wsdm_data = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\train_v2.csv\")\n",
    "\n",
    "# reading members csv\n",
    "members_data = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\members_v3.csv\")\n",
    "\n",
    "# merging train dataset with members dataset\n",
    "wsdm_members = pd.merge(wsdm_data, members_data, on='msno', how='left')\n",
    "# getting the head (top 5 rows) of df\n",
    "wsdm_members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.1 Loading files to merge-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "wsdm_data = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\train_v2.csv\")\n",
    "# members data\n",
    "members_data = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\members_v3.csv\")\n",
    "# transactions data\n",
    "transactions_data = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\transactions_v2.csv\")\n",
    "# user logs data\n",
    "logs_data = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\user_logs_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2 Merging files together-\n",
    "### 4.2.1 For train data-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170305.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>17599.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170301.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>8830.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7883.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170316.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9029.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20131223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20170310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1870.110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn  city    bd gender  \\\n",
       "0  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0   male   \n",
       "1  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0   male   \n",
       "2  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0   male   \n",
       "3  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0   male   \n",
       "4  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         1   5.0  28.0   male   \n",
       "\n",
       "   registered_via  registration_init_time  payment_method_id  \\\n",
       "0             3.0              20131223.0                NaN   \n",
       "1             3.0              20131223.0                NaN   \n",
       "2             3.0              20131223.0                NaN   \n",
       "3             3.0              20131223.0                NaN   \n",
       "4             3.0              20131223.0                NaN   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                NaN              NaN                 NaN            NaN   \n",
       "1                NaN              NaN                 NaN            NaN   \n",
       "2                NaN              NaN                 NaN            NaN   \n",
       "3                NaN              NaN                 NaN            NaN   \n",
       "4                NaN              NaN                 NaN            NaN   \n",
       "\n",
       "   transaction_date  membership_expire_date  is_cancel        date  num_25  \\\n",
       "0               NaN                     NaN        NaN  20170305.0     7.0   \n",
       "1               NaN                     NaN        NaN  20170301.0   138.0   \n",
       "2               NaN                     NaN        NaN  20170319.0     0.0   \n",
       "3               NaN                     NaN        NaN  20170316.0    15.0   \n",
       "4               NaN                     NaN        NaN  20170310.0     0.0   \n",
       "\n",
       "   num_50  num_75  num_985  num_100  num_unq  total_secs  \n",
       "0     0.0     3.0      5.0     71.0     68.0   17599.893  \n",
       "1    19.0     7.0      1.0     21.0    158.0    8830.433  \n",
       "2     0.0     0.0      0.0     34.0     17.0    7883.313  \n",
       "3     0.0     0.0      1.0     38.0     17.0    9029.227  \n",
       "4     0.0     0.0      0.0      8.0      8.0    1870.110  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging members data with train data\n",
    "wsdm_members = pd.merge(wsdm_data, members_data, on='msno', how='left')\n",
    "# merging transactions data with train members data\n",
    "wsdm_mem_trans = pd.merge(wsdm_members, transactions_data, on='msno', how='left')\n",
    "# merging user logs data with train members transaction data\n",
    "wsdm_dataset = pd.merge(wsdm_mem_trans, logs_data, on='msno', how='left')\n",
    "# getting head of train dataset\n",
    "pd.set_option('display.max_columns', 100)\n",
    "wsdm_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16887877, 23)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsdm_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample 50% of Data due to memory restrictions\n",
    "wsdm_dataset = wsdm_dataset.sample(frac=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20150913., 20111114., 20150701., ..., 20060329., 20110131.,\n",
       "       20150629.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since registration_init_time contains a lot of nan values so impute median date\n",
    "wsdm_dataset['registration_init_time'] = wsdm_dataset['registration_init_time'].fillna(20150204.0)\n",
    "# getting registration_init_time array\n",
    "reg_date = wsdm_dataset['registration_init_time'].values\n",
    "reg_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11821514"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing these train registrationn dates to npz file\n",
    "np.savez_compressed(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\wsdm_registration_date\", reg_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vorverarbeitung\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    '''This preprocess function is used to perform basic preprocessing on top of train and test dataset\n",
    "    These preprocessing consist outliers removal, nan imputation and replacing the values'''\n",
    "    \n",
    "    # imputing 0 in place of nan values in the city column\n",
    "    data['city'] = data['city'].fillna(0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['bd'] = data['bd'].apply(lambda x: x if (x < 72.0) and (x > 0.0) else np.nan)\n",
    "    # imputing 28 as age instead of nan\n",
    "    data['bd'] = data['bd'].fillna(28.0)\n",
    "\n",
    "    # replacing male with 1 in gender\n",
    "    data['gender'] = data['gender'].replace(to_replace='male', value=1)\n",
    "    # replacing male with 2 in gender\n",
    "    data['gender'] = data['gender'].replace(to_replace='female', value=2)\n",
    "    # replacing nan with 0 in gender\n",
    "    data['gender'] = data['gender'].fillna(0)\n",
    "\n",
    "    # replace 0 instead of nan in registered_via\n",
    "    data['registered_via'] = data['registered_via'].fillna(0)\n",
    "\n",
    "    # filling median date in place of nan in the df\n",
    "    data['registration_init_time'] = data['registration_init_time'].fillna(20150204.0)\n",
    "    # converting float date to datetime\n",
    "    data['registration_init_time'] = pd.to_datetime(data['registration_init_time'], format='%Y%m%d')\n",
    "\n",
    "    # imputing 0 in place of nan value in payment_method_id\n",
    "    data['payment_method_id'] = data['payment_method_id'].fillna(0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['payment_plan_days'] = data['payment_plan_days'].apply(lambda x: x if (x <= 30.0) else np.nan)\n",
    "    # imputing 30 in place of nan in payment_plan_days\n",
    "    data['payment_plan_days'] = data['payment_plan_days'].fillna(30.0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['plan_list_price'] = data['plan_list_price'].apply(lambda x: x if (x <= 180.0) else np.nan)\n",
    "    # imputing 149 in place of nan in plan_list_price\n",
    "    data['plan_list_price'] = data['plan_list_price'].fillna(149.0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['actual_amount_paid'] = data['actual_amount_paid'].apply(lambda x: x if (x <= 180.0) else np.nan)\n",
    "    # imputing 149 in place of nan in actual_amount_paid\n",
    "    data['actual_amount_paid'] = data['actual_amount_paid'].fillna(149.0)\n",
    "\n",
    "    # imputing 2 in place of nan values in is_auto_renew\n",
    "    data['is_auto_renew'] = data['is_auto_renew'].fillna(2)\n",
    "\n",
    "    # filling median date in place of nan in the df\n",
    "    data['transaction_date'] = data['transaction_date'].fillna(20170316.0)\n",
    "    # converting float date to datetime\n",
    "    data['transaction_date'] = pd.to_datetime(data['transaction_date'], format='%Y%m%d')\n",
    "\n",
    "    # filling median date in place of nan in the df\n",
    "    data['membership_expire_date'] = data['membership_expire_date'].fillna(20170419.0)\n",
    "    # converting float date to datetime\n",
    "    data['membership_expire_date'] = pd.to_datetime(data['membership_expire_date'], format='%Y%m%d')\n",
    "\n",
    "    # imputing 2 in place of nan values in is_cancel\n",
    "    data['is_cancel'] = data['is_cancel'].fillna(2)\n",
    "\n",
    "    # filling median date in place of nan in the df\n",
    "    data['date'] = data['date'].fillna(20170316.0)\n",
    "    # converting float date to datetime\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%Y%m%d')\n",
    "\n",
    "    # removing outliers\n",
    "    data['num_25'] = data['num_25'].apply(lambda x: x if (x <= 15.0) else np.nan)\n",
    "    # now I can impute 2 instead of nan in num_25\n",
    "    data['num_25'] = data['num_25'].fillna(2.0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['num_50'] = data['num_50'].apply(lambda x: x if (x <= 4.0) else np.nan)\n",
    "    # now I can impute 0 instead of nan in num_50\n",
    "    data['num_50'] = data['num_50'].fillna(0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['num_75'] = data['num_75'].apply(lambda x: x if (x <= 3.0) else np.nan)\n",
    "    # now I can impute 0 instead of nan in num_75\n",
    "    data['num_75'] = data['num_75'].fillna(0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['num_985'] = data['num_985'].apply(lambda x: x if (x <= 3.0) else np.nan)\n",
    "    # now I can impute 0 instead of nan in num_985\n",
    "    data['num_985'] = data['num_985'].fillna(0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['num_100'] = data['num_100'].apply(lambda x: x if (x <= 74.0) else np.nan)\n",
    "    # now I can impute 14 instead of nan in num_100\n",
    "    data['num_100'] = data['num_100'].fillna(14.0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['num_unq'] = data['num_unq'].apply(lambda x: x if (x <= 68.0) else np.nan)\n",
    "    # now I can impute 16 instead of nan in num_unq\n",
    "    data['num_unq'] = data['num_unq'].fillna(16.0)\n",
    "\n",
    "    # removing outliers\n",
    "    data['total_secs'] = data['total_secs'].apply(lambda x: x if (x <= 19167.549700000025) else np.nan)\n",
    "    # now I can impute 3880.765 instead of nan in total_secs\n",
    "    data['total_secs'] = data['total_secs'].fillna(3880.765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno                            0\n",
       "is_churn                        0\n",
       "city                        81908\n",
       "bd                          81908\n",
       "gender                    5503216\n",
       "registered_via              81908\n",
       "registration_init_time          0\n",
       "payment_method_id          238502\n",
       "payment_plan_days          238502\n",
       "plan_list_price            238502\n",
       "actual_amount_paid         238502\n",
       "is_auto_renew              238502\n",
       "transaction_date           238502\n",
       "membership_expire_date     238502\n",
       "is_cancel                  238502\n",
       "date                       174409\n",
       "num_25                     174409\n",
       "num_50                     174409\n",
       "num_75                     174409\n",
       "num_985                    174409\n",
       "num_100                    174409\n",
       "num_unq                    174409\n",
       "total_secs                 174409\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null values for train data\n",
    "# getting features wise null values (number)\n",
    "wsdm_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing preprocessing on top of entire train data\n",
    "preprocess(wsdm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again just to cross check if there is any null or not\n",
    "wsdm_dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any duplicate row\n",
    "wsdm_dataset.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving train file to disk\n",
    "wsdm_dataset.to_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading the files\n",
    "wsdm_dataset = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Feature - 4 to 12 (sum based features)\n",
    "# Feature - 13 to 19 (mean based features)\n",
    "# Feature - 20 to 27 (standard deviation based features)\n",
    "# Feature - 28 (nunique based feature)\n",
    "# Feature - 29 and 30 (min and max based features)\n",
    "# Feature - 31 to 33 (mean based features for transaction)\n",
    "# Feature - 34 (transaction count)\n",
    "# Feature - 35 (transaction date max)\n",
    "# Feature - 36 (membership expiry date max)\n",
    "# Feature - 37 (membership expiry date count)\n",
    "\n",
    "def std(x):\n",
    "    '''finding standard deviation using numpy,\n",
    "    to avoid getting nan values'''\n",
    "    return np.std(x)\n",
    "\n",
    "# grouping them together for train data\n",
    "temp_df_train = wsdm_dataset.groupby('msno').agg(num_25_sum=('num_25', 'sum'),\n",
    "                                num_50_sum=('num_50', 'sum'),\n",
    "                                num_75_sum=('num_75', 'sum'),\n",
    "                                num_985_sum=('num_985', 'sum'),\n",
    "                                num_100_sum=('num_100', 'sum'),\n",
    "                                num_unq_sum=('num_unq', 'sum'),\n",
    "                                total_secs_sum=('total_secs', 'sum'),\n",
    "                                num_25_mean=('num_25', 'mean'),\n",
    "                                num_50_mean=('num_50', 'mean'),\n",
    "                                num_75_mean=('num_75', 'mean'),\n",
    "                                num_985_mean=('num_985', 'mean'),\n",
    "                                num_100_mean=('num_100', 'mean'),\n",
    "                                num_unq_mean=('num_unq', 'mean'),\n",
    "                                total_secs_mean=('total_secs', 'mean'),\n",
    "                                num_25_std=('num_25', std),\n",
    "                                num_50_std=('num_50', std),\n",
    "                                num_75_std=('num_75', std),\n",
    "                                num_985_std=('num_985', std),\n",
    "                                num_100_std=('num_100', std),\n",
    "                                num_unq_std=('num_unq', std),\n",
    "                                total_secs_std=('total_secs', std),\n",
    "                                active_days=('date', 'nunique'),\n",
    "                                date_min=('date', 'min'),\n",
    "                                date_max=('date', 'max'),\n",
    "                                payment_plan_days_mean=('payment_plan_days', 'mean'),\n",
    "                                plan_list_price_mean=('plan_list_price', 'mean'),\n",
    "                                actual_amount_paid_mean=('actual_amount_paid', 'mean'),\n",
    "                                transaction_date_count=('transaction_date', 'nunique'),\n",
    "                                transaction_date_max=('transaction_date', 'max'),\n",
    "                                membership_expire_date_max=('membership_expire_date', 'max'),\n",
    "                                membership_expire_count=('membership_expire_date', 'nunique'))\n",
    "# merging them with the wsdm dataset\n",
    "wsdm_dataset = pd.merge(wsdm_dataset, temp_df_train, on='msno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://medium.com/@vincentteyssier/optimizing-the-size-of-a-pandas-dataframe-for-low-memory-environment-5f07db3d72e\n",
    "# reference: https://numpy.org/doc/stable/reference/generated/numpy.iinfo.html\n",
    "# reference: https://numpy.org/doc/stable/reference/generated/numpy.finfo.html\n",
    "\n",
    "def datatype_changer(dataset):\n",
    "    # iterating through all the columns in the dataframe\n",
    "    for col in dataset.columns:\n",
    "        # getting column's datatype\n",
    "        col_type = dataset[col].dtype\n",
    "        \n",
    "        # checking if datatype of column is 'object' or not\n",
    "        # if column type is not object\n",
    "        if (col_type == int) or (col_type == float):\n",
    "            # getting minimum value of a column\n",
    "            min_val = dataset[col].min()\n",
    "            # getting maximum value of a column\n",
    "            max_val = dataset[col].max()\n",
    "            # checking whether the datatype contain first 3 characters as int or not, if int\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # cheking the minimal and maximal value for int8, int16, int32 and int64 in numpy\n",
    "                if min_val > np.iinfo(np.int8).min and max_val < np.iinfo(np.int8).max:\n",
    "                    dataset[col] = dataset[col].astype(np.int8)\n",
    "                elif min_val > np.iinfo(np.int16).min and max_val < np.iinfo(np.int16).max:\n",
    "                    dataset[col] = dataset[col].astype(np.int16)\n",
    "                elif min_val > np.iinfo(np.int32).min and max_val < np.iinfo(np.int32).max:\n",
    "                    dataset[col] = dataset[col].astype(np.int32)\n",
    "                else:\n",
    "                    dataset[col] = dataset[col].astype(np.int64)\n",
    "            else:\n",
    "                # if it is non int, which is ultimately float\n",
    "                # cheking the minimal and maximal value for float16, float32 and float64 in numpy\n",
    "                if min_val > np.finfo(np.float16).min and max_val < np.finfo(np.float16).max:\n",
    "                    dataset[col] = dataset[col].astype(np.float16)\n",
    "                elif min_val > np.finfo(np.float32).min and max_val < np.finfo(np.float32).max:\n",
    "                    dataset[col] = dataset[col].astype(np.float32)\n",
    "                else:\n",
    "                    dataset[col] = dataset[col].astype(np.float64)\n",
    "        else:\n",
    "            # keeping rest of them to category datatype instead of object\n",
    "            dataset[col] = dataset[col].astype('category')\n",
    "            \n",
    "    # returning head of the dataframe\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsdm_dataset = datatype_changer(wsdm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving train file\n",
    "wsdm_dataset.to_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\wsdm_FA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Prepare Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading train dataset\n",
    "wsdm_dataset = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\wsdm_FA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing Rawdata Features\n",
    "# wsdm_dataset = wsdm_dataset.drop(['registration_init_time',\n",
    "#                               'transaction_date', \n",
    "#                               'membership_expire_date', \n",
    "#                               'date', \n",
    "#                               'num_25',\n",
    "#                               'num_50',\n",
    "#                               'num_75',\n",
    "#                               'num_985',\n",
    "#                               'num_100',\n",
    "#                               'num_unq',\n",
    "#                               'total_secs',\n",
    "#                               'is_weekend',\n",
    "#                               'is_weekday',\n",
    "#                               'day_of_the_week', \n",
    "#                               'date_min', \n",
    "#                               'date_max', \n",
    "#                               'transaction_date_max', \n",
    "#                               'membership_expire_date_max'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20150913., 20111114., 20150701., ..., 20060329., 20110131.,\n",
       "       20150629.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding registration init time feature to train dataset\n",
    "# load the registration array\n",
    "reg_date = np.load(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\wsdm_registration_date.npz\")\n",
    "# display the array\n",
    "reg_date['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11821514"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting numpy array to list\n",
    "registration_init_time = reg_date['arr_0'].tolist()\n",
    "# getting length of the list\n",
    "len(registration_init_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new feature, and adding it to train dataset\n",
    "wsdm_dataset['registration_init_time'] = registration_init_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving new dataset\n",
    "wsdm_dataset.to_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\prepared_train_incraw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['msno', 'is_churn', 'city', 'bd', 'gender', 'registered_via',\n",
       "       'registration_init_time', 'payment_method_id', 'payment_plan_days',\n",
       "       'plan_list_price', 'actual_amount_paid', 'is_auto_renew',\n",
       "       'transaction_date', 'membership_expire_date', 'is_cancel', 'date',\n",
       "       'num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq',\n",
       "       'total_secs', 'num_25_sum', 'num_50_sum', 'num_75_sum', 'num_985_sum',\n",
       "       'num_100_sum', 'num_unq_sum', 'total_secs_sum', 'num_25_mean',\n",
       "       'num_50_mean', 'num_75_mean', 'num_985_mean', 'num_100_mean',\n",
       "       'num_unq_mean', 'total_secs_mean', 'num_25_std', 'num_50_std',\n",
       "       'num_75_std', 'num_985_std', 'num_100_std', 'num_unq_std',\n",
       "       'total_secs_std', 'active_days', 'date_min', 'date_max',\n",
       "       'payment_plan_days_mean', 'plan_list_price_mean',\n",
       "       'actual_amount_paid_mean', 'transaction_date_count',\n",
       "       'transaction_date_max', 'membership_expire_date_max',\n",
       "       'membership_expire_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading csv file for removing duplicates\n",
    "wsdm_dataset = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\prepared_train_incraw.csv\")\n",
    "# getting all columns of train dataset\n",
    "wsdm_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11821514, 54)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting shape of train dataset\n",
    "wsdm_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting columns and converting them to list\n",
    "cols = wsdm_dataset.columns.tolist()\n",
    "# saving them for further use\n",
    "np.savez_compressed(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\columns_incraw.npz\", cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving actual train dataset\n",
    "wsdm_dataset.to_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_train_incraw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3.2 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading actual train data\n",
    "wsdm_data = pd.read_csv(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_train_incraw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing all nan and infinity to 0\n",
    "wsdm_data = wsdm_data.replace(np.nan, 0, inplace=False)\n",
    "wsdm_data = wsdm_data.replace(np.inf, 0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample 50% of Data due to memory restrictions\n",
    "wsdm_data = wsdm_data.sample(frac=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Typkonvertierungen\n",
    "wsdm_data['transaction_date_max'] = wsdm_data['transaction_date_max'].str.replace('-', '').astype(float)\n",
    "wsdm_data['membership_expire_date'] = wsdm_data['membership_expire_date'].str.replace('-', '').astype(float)\n",
    "wsdm_data['membership_expire_date_max'] = wsdm_data['membership_expire_date_max'].str.replace('-', '').astype(float)\n",
    "\n",
    "wsdm_data['transaction_date'] = wsdm_data['transaction_date'].str.replace('-', '').astype(float)\n",
    "wsdm_data['date'] = wsdm_data['date'].str.replace('-', '').astype(float)\n",
    "wsdm_data['date_min'] = wsdm_data['date_min'].str.replace('-', '').astype(float)\n",
    "wsdm_data['date_max'] = wsdm_data['date_max'].str.replace('-', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/29651514\n",
    "def normalize(df):\n",
    "    result1 = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        if (str(feature_name) != str('msno') and str(feature_name)!=str('is_churn')):\n",
    "            max_value = df[feature_name].max()\n",
    "            min_value = df[feature_name].min()\n",
    "            result1[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result1\n",
    "\n",
    "wsdm_dataset = normalize(wsdm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting labels for y\n",
    "labels = wsdm_dataset['is_churn'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>...</th>\n",
       "      <th>active_days</th>\n",
       "      <th>date_min</th>\n",
       "      <th>date_max</th>\n",
       "      <th>payment_plan_days_mean</th>\n",
       "      <th>plan_list_price_mean</th>\n",
       "      <th>actual_amount_paid_mean</th>\n",
       "      <th>transaction_date_count</th>\n",
       "      <th>transaction_date_max</th>\n",
       "      <th>membership_expire_date_max</th>\n",
       "      <th>membership_expire_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5084845</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.690658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.009662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230250</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.773724</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.999110</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.009662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349976</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.929818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226464</th>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.156786</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.004831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357228</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.846052</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998715</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051007</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.695196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893667</td>\n",
       "      <td>0.682222</td>\n",
       "      <td>0.732222</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.331529</td>\n",
       "      <td>0.125604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292551</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.229891</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.004831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9193532</th>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.310573</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10151992</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.696704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781520</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.772993</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.827778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5910757 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              city        bd  gender  registered_via  registration_init_time  \\\n",
       "5084845   0.045455  0.385714     0.0        0.538462                0.690658   \n",
       "10230250  0.045455  0.214286     1.0        0.230769                0.773724   \n",
       "8349976   0.045455  0.385714     0.0        0.538462                0.929818   \n",
       "3226464   0.681818  0.328571     0.5        0.692308                0.156786   \n",
       "357228    0.227273  0.257143     0.5        0.230769                0.846052   \n",
       "...            ...       ...     ...             ...                     ...   \n",
       "4051007   0.045455  0.385714     0.0        0.538462                0.695196   \n",
       "9292551   0.500000  0.428571     0.5        0.692308                0.229891   \n",
       "9193532   0.590909  0.371429     1.0        0.692308                0.310573   \n",
       "10151992  0.045455  0.385714     0.0        0.538462                0.696704   \n",
       "6781520   0.227273  0.442857     0.5        0.692308                0.772993   \n",
       "\n",
       "          payment_method_id  payment_plan_days  plan_list_price  \\\n",
       "5084845            1.000000                1.0         0.827778   \n",
       "10230250           0.414634                1.0         0.000000   \n",
       "8349976            1.000000                1.0         0.550000   \n",
       "3226464            0.951220                1.0         0.827778   \n",
       "357228             0.878049                1.0         1.000000   \n",
       "...                     ...                ...              ...   \n",
       "4051007            1.000000                1.0         0.827778   \n",
       "9292551            0.951220                1.0         0.827778   \n",
       "9193532            0.878049                1.0         1.000000   \n",
       "10151992           1.000000                1.0         0.550000   \n",
       "6781520            0.756098                1.0         0.827778   \n",
       "\n",
       "          actual_amount_paid  is_auto_renew  ...  active_days  date_min  \\\n",
       "5084845             0.827778            0.5  ...     0.966667  0.000000   \n",
       "10230250            0.000000            0.0  ...     0.733333  0.266667   \n",
       "8349976             0.550000            0.5  ...     0.600000  0.066667   \n",
       "3226464             0.827778            0.5  ...     0.766667  0.000000   \n",
       "357228              1.000000            0.0  ...     0.700000  0.033333   \n",
       "...                      ...            ...  ...          ...       ...   \n",
       "4051007             0.661111            0.5  ...     0.600000  0.000000   \n",
       "9292551             0.827778            0.5  ...     0.766667  0.000000   \n",
       "9193532             1.000000            0.5  ...     0.633333  0.000000   \n",
       "10151992            0.550000            0.5  ...     0.000000  0.500000   \n",
       "6781520             0.827778            0.5  ...     0.533333  0.000000   \n",
       "\n",
       "          date_max  payment_plan_days_mean  plan_list_price_mean  \\\n",
       "5084845   1.000000                1.000000              0.827778   \n",
       "10230250  1.000000                1.000000              0.490000   \n",
       "8349976   0.966667                1.000000              0.550000   \n",
       "3226464   1.000000                1.000000              0.827778   \n",
       "357228    0.966667                1.000000              1.000000   \n",
       "...            ...                     ...                   ...   \n",
       "4051007   1.000000                0.893667              0.682222   \n",
       "9292551   1.000000                1.000000              0.827778   \n",
       "9193532   0.966667                1.000000              1.000000   \n",
       "10151992  0.500000                1.000000              0.550000   \n",
       "6781520   1.000000                1.000000              0.827778   \n",
       "\n",
       "          actual_amount_paid_mean  transaction_date_count  \\\n",
       "5084845                  0.827778                0.041667   \n",
       "10230250                 0.490000                0.041667   \n",
       "8349976                  0.550000                0.000000   \n",
       "3226464                  0.827778                0.020833   \n",
       "357228                   1.000000                0.000000   \n",
       "...                           ...                     ...   \n",
       "4051007                  0.732222                0.500000   \n",
       "9292551                  0.827778                0.020833   \n",
       "9193532                  1.000000                0.000000   \n",
       "10151992                 0.550000                0.000000   \n",
       "6781520                  0.827778                0.000000   \n",
       "\n",
       "          transaction_date_max  membership_expire_date_max  \\\n",
       "5084845               0.999160                    0.006338   \n",
       "10230250              0.999110                    0.006338   \n",
       "8349976               0.998764                    0.002938   \n",
       "3226464               1.000000                    0.004902   \n",
       "357228                0.998715                    0.002905   \n",
       "...                        ...                         ...   \n",
       "4051007               0.999802                    0.331529   \n",
       "9292551               1.000000                    0.004869   \n",
       "9193532               0.999258                    0.003086   \n",
       "10151992              0.998616                    0.002888   \n",
       "6781520               1.000000                    0.003334   \n",
       "\n",
       "          membership_expire_count  \n",
       "5084845                  0.009662  \n",
       "10230250                 0.009662  \n",
       "8349976                  0.000000  \n",
       "3226464                  0.004831  \n",
       "357228                   0.000000  \n",
       "...                           ...  \n",
       "4051007                  0.125604  \n",
       "9292551                  0.004831  \n",
       "9193532                  0.000000  \n",
       "10151992                 0.000000  \n",
       "6781520                  0.000000  \n",
       "\n",
       "[5910757 rows x 52 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting labels for X\n",
    "data = wsdm_dataset.drop(['msno', 'is_churn'], axis=1, inplace=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4137529, 52) (4137529,)\n",
      "(1773228, 52) (1773228,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04545455, 0.38571429, 0.        , ..., 0.99945623, 0.00316889,\n",
       "        0.        ],\n",
       "       [0.04545455, 0.38571429, 0.        , ..., 0.99851698, 0.00293783,\n",
       "        0.        ],\n",
       "       [0.59090909, 0.22857143, 1.        , ..., 0.99851698, 0.0028553 ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.04545455, 0.38571429, 0.        , ..., 0.99906075, 0.00302035,\n",
       "        0.        ],\n",
       "       [0.36363636, 0.3       , 1.        , ..., 1.        , 0.00457179,\n",
       "        0.00483092],\n",
       "       [0.04545455, 0.38571429, 0.        , ..., 1.        , 0.00333394,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting X_train to numpy array\n",
    "wsdm_arr = X_train.values\n",
    "wsdm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4137529, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of train array\n",
    "wsdm_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it for further use\n",
    "np.savez_compressed(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_train_incraw.npz\", wsdm_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying y_train\n",
    "wsdm_labels_arr = y_train\n",
    "wsdm_labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4137529,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of train labels\n",
    "wsdm_labels_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it for further use\n",
    "np.savez_compressed(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_wsdm_labels_incraw.npz\", wsdm_labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.37142857, 1.        , ..., 0.99861585, 0.00290482,\n",
       "        0.        ],\n",
       "       [0.04545455, 0.38571429, 0.        , ..., 0.99965396, 0.00323491,\n",
       "        0.        ],\n",
       "       [0.04545455, 0.38571429, 0.        , ..., 1.        , 0.00333394,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.04545455, 0.4       , 0.5       , ..., 0.99925849, 0.00315239,\n",
       "        0.        ],\n",
       "       [0.27272727, 0.37142857, 1.        , ..., 0.99881358, 0.00293783,\n",
       "        0.        ],\n",
       "       [0.18181818, 0.54285714, 0.5       , ..., 1.        , 0.17453663,\n",
       "        0.09178744]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting X_test to numpy array\n",
    "cv_arr = X_test.values\n",
    "cv_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773228, 52)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of cv array\n",
    "cv_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it for further use\n",
    "np.savez_compressed(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_cv_incraw.npz\", cv_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying y_test\n",
    "cv_labels_arr = y_test\n",
    "cv_labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773228,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of cv labels array\n",
    "cv_labels_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it for further use\n",
    "np.savez_compressed(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_cv_labels_incraw.npz\", cv_labels_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://machinelearningmastery.com/how-to-save-a-numpy-array-to-file-for-machine-learning/\n",
    "X_train = np.load(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_train_incraw.npz\")\n",
    "y_train = np.load(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_wsdm_labels_incraw.npz\")\n",
    "X_test = np.load(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_cv_incraw.npz\")\n",
    "y_test = np.load(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\actual_cv_labels_incraw.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4137529, 52) (4137529,)\n",
      "(1773228, 52) (1773228,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train['arr_0']\n",
    "X_test = X_test['arr_0']\n",
    "y_train = y_train['arr_0']\n",
    "y_test = y_test['arr_0']\n",
    "\n",
    "# getting shapes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading columns\n",
    "cols = np.load(r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\columns_incraw.npz\")\n",
    "# converting numpy array to python list\n",
    "cols = cols['arr_0'].tolist()\n",
    "# removing first two cols 'msno' and 'is_churn'\n",
    "cols = cols[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', n_jobs=-1, solver='newton-cg')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fitting logistic regression model with best parameter values\n",
    "lr_model = LogisticRegression(penalty='l2', tol=0.0001, C=10, solver='newton-cg', class_weight='balanced', n_jobs=-1)\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Work_Masterarbeit\\\\wsdm\\\\preprocessed_2\\\\finalized_model_lr_incraw.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/#:~:text=Saving%20Your%20Model-,Save%20Your%20Model%20with%20pickle,it%20to%20make%20new%20predictions.\n",
    "# saving the trained logistic regression ML model\n",
    "filename = r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\finalized_model_lr_incraw.sav\"\n",
    "joblib.dump(lr_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best model from disk\n",
    "filename = r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\finalized_model_lr_incraw.sav\"\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8361953454378117\n",
      "F1 score weighted: 0.8597320170509911\n",
      "F1 score macro: 0.6927865268652117\n",
      "Recall: 0.8361953454378117\n",
      "Precision: 0.9046498825165213\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90   1591796\n",
      "           1       0.36      0.75      0.48    181432\n",
      "\n",
      "    accuracy                           0.84   1773228\n",
      "   macro avg       0.66      0.80      0.69   1773228\n",
      "weighted avg       0.90      0.84      0.86   1773228\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[1347145  244651]\n",
      " [  45812  135620]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_predict=lr_model.predict(X_test)\n",
    "lr_predict\n",
    "\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, lr_predict))\n",
    "print('F1 score weighted:', f1_score(y_test, lr_predict,average='weighted'))\n",
    "print('F1 score macro:', f1_score(y_test, lr_predict, average='macro'))\n",
    "print('Recall:', recall_score(y_test, lr_predict,average='weighted'))\n",
    "print('Precision:', precision_score(y_test, lr_predict,average='weighted'))\n",
    "print('\\n clasification report:\\n', classification_report(y_test, lr_predict))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(y_test, lr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test log-loss:  0.4634192368521652\n"
     ]
    }
   ],
   "source": [
    "## Logloss\n",
    "# predicting probabilities for X_cv\n",
    "pred_test = loaded_model.predict_proba(X_test)\n",
    "# getting probabilities corresponding to class label 1 only\n",
    "pred_test = pred_test[:,1]\n",
    "# calculating log loss\n",
    "print('Test log-loss: ', log_loss(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_split=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# training a decision tree classifier model with best parameters\n",
    "dtc_model = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=5, min_samples_split=3, min_samples_leaf=1)\n",
    "dtc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Work_Masterarbeit\\\\wsdm\\\\preprocessed_2\\\\finalized_model_dtc_incraw.sav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/#:~:text=Saving%20Your%20Model-,Save%20Your%20Model%20with%20pickle,it%20to%20make%20new%20predictions.\n",
    "# saving the decision tree classifier model\n",
    "filename = r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\finalized_model_dtc_incraw.sav\"\n",
    "joblib.dump(dtc_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best decision tree classifier model from disk\n",
    "filename = r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\finalized_model_dtc_incraw.sav\"\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9626404500718464\n",
      "F1 score weighted: 0.9614834330563252\n",
      "F1 score macro: 0.8920651684509531\n",
      "Recall: 0.9626404500718464\n",
      "Precision: 0.9612149001144429\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98   1591796\n",
      "           1       0.86      0.75      0.80    181432\n",
      "\n",
      "    accuracy                           0.96   1773228\n",
      "   macro avg       0.92      0.87      0.89   1773228\n",
      "weighted avg       0.96      0.96      0.96   1773228\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[1570426   21370]\n",
      " [  44877  136555]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtc_modelpred=dtc_model.predict(X_test)\n",
    "dtc_modelpred\n",
    "\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, dtc_modelpred))\n",
    "print('F1 score weighted:', f1_score(y_test, dtc_modelpred,average='weighted'))\n",
    "print('F1 score macro:', f1_score(y_test, dtc_modelpred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, dtc_modelpred,average='weighted'))\n",
    "print('Precision:', precision_score(y_test, dtc_modelpred,average='weighted'))\n",
    "print('\\n clasification report:\\n', classification_report(y_test, dtc_modelpred))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(y_test, dtc_modelpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test log-loss:  0.1253341464733862\n"
     ]
    }
   ],
   "source": [
    "## Logloss\n",
    "# predicting probabilities for X_cv\n",
    "pred_test = loaded_model.predict_proba(X_test)\n",
    "# getting probabilities corresponding to class label 1 only\n",
    "pred_test = pred_test[:,1]\n",
    "# calculating log loss\n",
    "print('Test log-loss: ', log_loss(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=15, max_features='sqrt',\n",
       "                       min_samples_leaf=2, min_samples_split=3,\n",
       "                       n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# training the random forest classifier for best hyper parameters\n",
    "rf_model = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=15, min_samples_split=3, min_samples_leaf=2, max_features='sqrt', bootstrap=False, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Work_Masterarbeit\\\\wsdm\\\\preprocessed_2\\\\finalized_model_rf_incraw.sav']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/#:~:text=Saving%20Your%20Model-,Save%20Your%20Model%20with%20pickle,it%20to%20make%20new%20predictions.\n",
    "# saving the decision tree classifier model\n",
    "filename = r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\finalized_model_rf_incraw.sav\"\n",
    "joblib.dump(rf_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best model from disk\n",
    "filename = r\"D:\\Work_Masterarbeit\\wsdm\\preprocessed_2\\finalized_model_rf_incraw.sav\"\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9789282596485054\n",
      "F1 score weighted: 0.978328114519355\n",
      "F1 score macro: 0.9394031623497037\n",
      "Recall: 0.9789282596485054\n",
      "Precision: 0.9785531199361152\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99   1591796\n",
      "           1       0.95      0.84      0.89    181432\n",
      "\n",
      "    accuracy                           0.98   1773228\n",
      "   macro avg       0.97      0.92      0.94   1773228\n",
      "weighted avg       0.98      0.98      0.98   1773228\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[1583986    7810]\n",
      " [  29555  151877]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_modelpred=rf_model.predict(X_test)\n",
    "rf_modelpred\n",
    "\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, rf_modelpred))\n",
    "print('F1 score weighted:', f1_score(y_test, rf_modelpred,average='weighted'))\n",
    "print('F1 score macro:', f1_score(y_test, rf_modelpred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, rf_modelpred,average='weighted'))\n",
    "print('Precision:', precision_score(y_test, rf_modelpred,average='weighted'))\n",
    "print('\\n clasification report:\\n', classification_report(y_test, rf_modelpred))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(y_test, rf_modelpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test log-loss:  0.0701262256468004\n"
     ]
    }
   ],
   "source": [
    "## Logloss\n",
    "# predicting probabilities for X_cv\n",
    "pred_test = loaded_model.predict_proba(X_test)\n",
    "# getting probabilities corresponding to class label 1 only\n",
    "pred_test = pred_test[:,1]\n",
    "# calculating log loss\n",
    "print('Test log-loss: ', log_loss(y_test, pred_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOlBJ/DHS1tE19RvmuJAd/k",
   "collapsed_sections": [],
   "name": "BASELINE_WSDM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
